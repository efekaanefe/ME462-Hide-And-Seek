{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46a4e20f",
   "metadata": {},
   "source": [
    "MediaPipe Tracking Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e664b856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744636259.106506   86501 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1744636259.107724   88741 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.0.9-0ubuntu0.2), renderer: Mesa Intel(R) UHD Graphics 630 (CFL GT2)\n",
      "W0000 00:00:1744636259.173270   88731 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1744636259.208615   88727 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📸 Running for 10 seconds...\n",
      "\n",
      "=== Benchmark Results (10s) ===\n",
      "Total frames: 282\n",
      "Total time: 10.15 s\n",
      "Average FPS: 27.79\n",
      "Average Pose Detection Time: 21.49 ms\n",
      "Average CPU Usage: 15.79%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=1,\n",
    "    enable_segmentation=False,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5,\n",
    ")\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ Error: Cannot access the webcam.\")\n",
    "    exit()\n",
    "\n",
    "# Benchmarking setup\n",
    "start_time = time.time()\n",
    "frame_count = 0\n",
    "total_pose_time = 0.0\n",
    "cpu_usages = []\n",
    "\n",
    "print(\"📸 Running for 10 seconds...\")\n",
    "\n",
    "while True:\n",
    "    current_time = time.time()\n",
    "    if current_time - start_time > 10:\n",
    "        break\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"❌ Failed to read frame.\")\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Measure CPU usage before processing\n",
    "    cpu_usage = psutil.cpu_percent(interval=None)\n",
    "    cpu_usages.append(cpu_usage)\n",
    "\n",
    "    # Pose detection\n",
    "    t0 = time.time()\n",
    "    results = pose.process(rgb_frame)\n",
    "    t1 = time.time()\n",
    "    pose_time = t1 - t0\n",
    "    total_pose_time += pose_time\n",
    "    frame_count += 1\n",
    "\n",
    "    # Draw landmarks\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame,\n",
    "            results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2),\n",
    "        )\n",
    "\n",
    "    # Overlay metrics\n",
    "    elapsed = current_time - start_time\n",
    "    fps = frame_count / elapsed if elapsed > 0 else 0\n",
    "    cv2.putText(frame, f\"FPS: {fps:.2f}\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Pose Time: {pose_time * 1000:.1f} ms\", (10, 60),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "    cv2.putText(frame, f\"CPU: {cpu_usage:.1f}%\", (10, 90),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "    # Show frame\n",
    "    cv2.imshow(\"MediaPipe Pose Benchmark\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Summary\n",
    "total_time = time.time() - start_time\n",
    "avg_fps = frame_count / total_time if total_time > 0 else 0\n",
    "avg_pose_time = (total_pose_time / frame_count) * 1000 if frame_count > 0 else 0\n",
    "avg_cpu = sum(cpu_usages) / len(cpu_usages) if cpu_usages else 0\n",
    "\n",
    "print(\"\\n=== Benchmark Results (10s) ===\")\n",
    "print(f\"Total frames: {frame_count}\")\n",
    "print(f\"Total time: {total_time:.2f} s\")\n",
    "print(f\"Average FPS: {avg_fps:.2f}\")\n",
    "print(f\"Average Pose Detection Time: {avg_pose_time:.2f} ms\")\n",
    "print(f\"Average CPU Usage: {avg_cpu:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
