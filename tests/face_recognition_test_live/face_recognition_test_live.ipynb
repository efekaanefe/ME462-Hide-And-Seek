{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a4c6167",
   "metadata": {},
   "source": [
    "Dlib Recognition Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d10d01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 17:39:25.307216: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744814365.323041  133572 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744814365.327676  133572 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744814365.339864  133572 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744814365.339879  133572 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744814365.339880  133572 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744814365.339882  133572 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-16 17:39:25.343615: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install `face_recognition_models` with this command before using `face_recognition`:\n",
      "\n",
      "pip install git+https://github.com/ageitgey/face_recognition_models\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'quit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/face_recognition/api.py:9\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mface_recognition_models\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/face_recognition_models/__init__.py:7\u001b[39m\n\u001b[32m      5\u001b[39m __version__ = \u001b[33m'\u001b[39m\u001b[33m0.1.0\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mpkg_resources\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resource_filename\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mpose_predictor_model_location\u001b[39m():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pkg_resources/__init__.py:2172\u001b[39m\n\u001b[32m   2169\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(dist_groups, ())\n\u001b[32m-> \u001b[39m\u001b[32m2172\u001b[39m register_finder(\u001b[43mpkgutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImpImporter\u001b[49m, find_on_path)\n\u001b[32m   2174\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(importlib_machinery, \u001b[33m'\u001b[39m\u001b[33mFileFinder\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[31mAttributeError\u001b[39m: module 'pkgutil' has no attribute 'ImpImporter'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mmediapipe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mmp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mface_recognition\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mpickle\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtime\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/face_recognition/__init__.py:7\u001b[39m\n\u001b[32m      4\u001b[39m __email__ = \u001b[33m'\u001b[39m\u001b[33mageitgey@gmail.com\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      5\u001b[39m __version__ = \u001b[33m'\u001b[39m\u001b[33m1.2.3\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_image_file, face_locations, batch_face_locations, face_landmarks, face_encodings, compare_faces, face_distance\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/face_recognition/api.py:13\u001b[39m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPlease install `face_recognition_models` with this command before using `face_recognition`:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpip install git+https://github.com/ageitgey/face_recognition_models\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[43mquit\u001b[49m()\n\u001b[32m     15\u001b[39m ImageFile.LOAD_TRUNCATED_IMAGES = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     17\u001b[39m face_detector = dlib.get_frontal_face_detector()\n",
      "\u001b[31mNameError\u001b[39m: name 'quit' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import face_recognition\n",
    "import pickle\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "# === Load known face encodings ===\n",
    "with open(\"known_faces_dlib.pkl\", \"rb\") as f:\n",
    "    known_faces = pickle.load(f)\n",
    "\n",
    "known_encodings = []\n",
    "known_names = []\n",
    "for name, enc_list in known_faces.items():\n",
    "    for enc in enc_list:\n",
    "        known_encodings.append(enc)\n",
    "        known_names.append(name)\n",
    "\n",
    "# === Initialize MediaPipe Face Detection ===\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "face_detection = mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5)\n",
    "\n",
    "# === Webcam ===\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Failed to open webcam.\")\n",
    "    exit()\n",
    "\n",
    "# === Benchmark Variables ===\n",
    "start_time = time.time()\n",
    "frame_count = 0\n",
    "total_faces_detected = 0\n",
    "cpu_usages = []\n",
    "\n",
    "# === Timing Limit ===\n",
    "DURATION = 1000  # seconds\n",
    "\n",
    "print(\"üé• Running real-time recognition for 10 seconds...\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    now = time.time()\n",
    "    if now - start_time > DURATION:\n",
    "        break\n",
    "\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    cpu_usages.append(psutil.cpu_percent(interval=None))\n",
    "\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_detection.process(rgb)\n",
    "\n",
    "    if results.detections:\n",
    "        total_faces_detected += len(results.detections)\n",
    "\n",
    "        for detection in results.detections:\n",
    "            bbox = detection.location_data.relative_bounding_box\n",
    "            h, w, _ = frame.shape\n",
    "            x = int(bbox.xmin * w)\n",
    "            y = int(bbox.ymin * h)\n",
    "            width = int(bbox.width * w)\n",
    "            height = int(bbox.height * h)\n",
    "\n",
    "            x = max(0, x)\n",
    "            y = max(0, y)\n",
    "            width = min(w - x, width)\n",
    "            height = min(h - y, height)\n",
    "\n",
    "            face_location = (y, x + width, y + height, x)\n",
    "\n",
    "            name = \"Unknown\"\n",
    "            encodings = face_recognition.face_encodings(rgb, known_face_locations=[face_location])\n",
    "            if encodings:\n",
    "                encoding = encodings[0]\n",
    "                matches = face_recognition.compare_faces(known_encodings, encoding)\n",
    "                face_distances = face_recognition.face_distance(known_encodings, encoding)\n",
    "                if any(matches):\n",
    "                    best_match_index = face_distances.argmin()\n",
    "                    name = known_names[best_match_index]\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, name, (x, y - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # === Display FPS and CPU Usage ===\n",
    "    elapsed = now - start_time\n",
    "    fps = frame_count / elapsed if elapsed > 0 else 0\n",
    "    current_cpu = cpu_usages[-1] if cpu_usages else 0\n",
    "\n",
    "    cv2.putText(frame, f\"FPS: {fps:.2f}\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "    cv2.putText(frame, f\"CPU: {current_cpu:.1f}%\", (10, 60),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 100, 100), 2)\n",
    "\n",
    "    cv2.imshow(\"Face Recognition\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# === Results ===\n",
    "end_time = time.time()\n",
    "avg_fps = frame_count / (end_time - start_time)\n",
    "avg_cpu = sum(cpu_usages) / len(cpu_usages) if cpu_usages else 0\n",
    "\n",
    "print(\"\\nüìä Benchmark Results:\")\n",
    "print(f\"üïí Runtime: {end_time - start_time:.2f} seconds\")\n",
    "print(f\"üñºÔ∏è Frames processed: {frame_count}\")\n",
    "print(f\"üìà Average FPS: {avg_fps:.2f}\")\n",
    "print(f\"üë• Total faces detected: {total_faces_detected}\")\n",
    "print(f\"üß† Average CPU usage: {avg_cpu:.2f}%\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e57922",
   "metadata": {},
   "source": [
    "Arcface Recognition Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85711650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/maksimgorki/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/maksimgorki/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/maksimgorki/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/maksimgorki/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/maksimgorki/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "üé• Starting ArcFace Recognition for 10 seconds...\n",
      "‚úÖ First frame acquired, starting timer...\n",
      "\n",
      "üìä Benchmark Results:\n",
      "üïí Runtime: 21.86 seconds\n",
      "üñºÔ∏è Frames processed: 141\n",
      "üìà Average FPS: 6.45\n",
      "üë• Total faces detected: 59\n",
      "üß† Average CPU usage: 65.76%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import insightface\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "# === Suppress logs ===\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"INSIGHTFACE_LOG_LEVEL\"] = \"ERROR\"\n",
    "\n",
    "# === Load known embeddings ===\n",
    "with open(\"known_faces_arcface.pkl\", \"rb\") as f:\n",
    "    raw_faces = pickle.load(f)\n",
    "\n",
    "known_names = []\n",
    "known_embeddings = []\n",
    "\n",
    "for name, embeddings in raw_faces.items():\n",
    "    for emb in embeddings:\n",
    "        norm_emb = emb / np.linalg.norm(emb)\n",
    "        known_names.append(name)\n",
    "        known_embeddings.append(norm_emb)\n",
    "\n",
    "# === Init InsightFace ===\n",
    "model = insightface.app.FaceAnalysis(name='buffalo_l')\n",
    "model.prepare(ctx_id=0)  # GPU=0, CPU=-1\n",
    "\n",
    "# === Webcam feed ===\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Failed to open webcam.\")\n",
    "    exit()\n",
    "\n",
    "# === Constants and Benchmark Vars ===\n",
    "DURATION = 1000  # seconds\n",
    "frame_count = 0\n",
    "total_faces_detected = 0\n",
    "cpu_usages = []\n",
    "\n",
    "print(\"üé• Starting ArcFace Recognition for 10 seconds...\")\n",
    "\n",
    "# Wait for first frame before starting timer\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        break\n",
    "print(\"‚úÖ First frame acquired, starting timer...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# === Main Loop ===\n",
    "while cap.isOpened():\n",
    "    now = time.time()\n",
    "    if now - start_time > DURATION:\n",
    "        break\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    cpu_usages.append(psutil.cpu_percent(interval=None))\n",
    "\n",
    "    faces = model.get(frame)\n",
    "\n",
    "    if faces:\n",
    "        total_faces_detected += len(faces)\n",
    "\n",
    "    for face in faces:\n",
    "        x1, y1, x2, y2 = face.bbox.astype(int)\n",
    "        embedding = face.embedding / np.linalg.norm(face.embedding)\n",
    "\n",
    "        name = \"Unknown\"\n",
    "        similarities = [np.dot(embedding, k) for k in known_embeddings]\n",
    "        best_index = int(np.argmax(similarities))\n",
    "        best_score = similarities[best_index]\n",
    "\n",
    "        if best_score > 0.36:\n",
    "            name = known_names[best_index]\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, name, (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "    # === Show FPS and CPU on screen ===\n",
    "    elapsed = now - start_time\n",
    "    fps = frame_count / elapsed if elapsed > 0 else 0\n",
    "    current_cpu = cpu_usages[-1] if cpu_usages else 0\n",
    "\n",
    "    cv2.putText(frame, f\"FPS: {fps:.2f}\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "    cv2.putText(frame, f\"CPU: {current_cpu:.1f}%\", (10, 60),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 100, 100), 2)\n",
    "\n",
    "    cv2.imshow(\"ArcFace Recognition\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# === Summary ===\n",
    "end_time = time.time()\n",
    "avg_fps = frame_count / (end_time - start_time)\n",
    "avg_cpu = sum(cpu_usages) / len(cpu_usages) if cpu_usages else 0\n",
    "\n",
    "print(\"\\nüìä Benchmark Results:\")\n",
    "print(f\"üïí Runtime: {end_time - start_time:.2f} seconds\")\n",
    "print(f\"üñºÔ∏è Frames processed: {frame_count}\")\n",
    "print(f\"üìà Average FPS: {avg_fps:.2f}\")\n",
    "print(f\"üë• Total faces detected: {total_faces_detected}\")\n",
    "print(f\"üß† Average CPU usage: {avg_cpu:.2f}%\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f0af9c",
   "metadata": {},
   "source": [
    "Deepface Recogniiton Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8540b8b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'inspect' has no attribute 'ArgSpec'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mpickle\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mdeepface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepFace\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtime\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mpsutil\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/deepface/DeepFace.py:20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m package_utils, folder_utils\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommons\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Logger\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     21\u001b[39m     modeling,\n\u001b[32m     22\u001b[39m     representation,\n\u001b[32m     23\u001b[39m     verification,\n\u001b[32m     24\u001b[39m     recognition,\n\u001b[32m     25\u001b[39m     demography,\n\u001b[32m     26\u001b[39m     detection,\n\u001b[32m     27\u001b[39m     streaming,\n\u001b[32m     28\u001b[39m     preprocessing,\n\u001b[32m     29\u001b[39m )\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mdeepface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m     32\u001b[39m logger = Logger()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/deepface/modules/modeling.py:5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# project dependencies\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfacial_recognition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      6\u001b[39m     VGGFace,\n\u001b[32m      7\u001b[39m     OpenFace,\n\u001b[32m      8\u001b[39m     FbDeepFace,\n\u001b[32m      9\u001b[39m     DeepID,\n\u001b[32m     10\u001b[39m     ArcFace,\n\u001b[32m     11\u001b[39m     SFace,\n\u001b[32m     12\u001b[39m     Dlib,\n\u001b[32m     13\u001b[39m     Facenet,\n\u001b[32m     14\u001b[39m     GhostFaceNet,\n\u001b[32m     15\u001b[39m )\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mface_detection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     FastMtCnn,\n\u001b[32m     18\u001b[39m     MediaPipe,\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m     CenterFace,\n\u001b[32m     27\u001b[39m )\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdemography\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Age, Gender, Race, Emotion\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/deepface/models/facial_recognition/VGGFace.py:6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mnp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m package_utils, folder_utils\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m verification\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mFacialRecognition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FacialRecognition\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommons\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Logger\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/deepface/modules/verification.py:9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mnp\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# project dependencies\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m representation, detection, modeling\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mFacialRecognition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FacialRecognition\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommons\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Logger\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/deepface/modules/representation.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# project dependencies\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image_utils\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m modeling, detection, preprocessing\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mdeepface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mFacialRecognition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FacialRecognition\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mrepresent\u001b[39m(\n\u001b[32m     14\u001b[39m     img_path: Union[\u001b[38;5;28mstr\u001b[39m, np.ndarray],\n\u001b[32m     15\u001b[39m     model_name: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mVGG-Face\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m     max_faces: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     23\u001b[39m ) -> List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/deepface/modules/preprocessing.py:16\u001b[39m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m tf_major_version == \u001b[32m2\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mnormalize_input\u001b[39m(img: np.ndarray, normalization: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mbase\u001b[39m\u001b[33m\"\u001b[39m) -> np.ndarray:\n\u001b[32m     20\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Normalize input image.\u001b[39;00m\n\u001b[32m     21\u001b[39m \n\u001b[32m     22\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m \u001b[33;03m        numpy array: the normalized image.\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras/api/_v2/keras/__init__.py:12\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[33;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01m_sys\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_v2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_v2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras/__init__.py:21\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[32m     16\u001b[39m \n\u001b[32m     17\u001b[39m \u001b[33;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[33;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras/models/__init__.py:18\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras/engine/functional.py:26\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mtf\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layout_map \u001b[38;5;28;01mas\u001b[39;00m layout_map_lib\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras/backend.py:34\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_config\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_coordinator_utils \u001b[38;5;28;01mas\u001b[39;00m dc\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tensor\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_flow_util\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m object_identity\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras/engine/keras_tensor.py:19\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Keras Input Tensor used to track functional API Topology.\"\"\"\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mtf\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m object_identity\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structure\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras/utils/__init__.py:17\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Public Keras utilities.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msaving\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlegacy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mserialization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deserialize_keras_object\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msaving\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlegacy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mserialization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialize_keras_object\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Serialization related\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras/saving/legacy/serialization.py:24\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mtf\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_contextlib\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_inspect\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras/utils/tf_inspect.py:22\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01minspect\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01m_inspect\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mtf\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m ArgSpec = \u001b[43m_inspect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mArgSpec\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(_inspect, \u001b[33m\"\u001b[39m\u001b[33mFullArgSpec\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     26\u001b[39m     FullArgSpec = _inspect.FullArgSpec\n",
      "\u001b[31mAttributeError\u001b[39m: module 'inspect' has no attribute 'ArgSpec'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "from deepface import DeepFace\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "# === Settings ===\n",
    "ENCODING_FILE = \"known_faces_deepface.pkl\"\n",
    "MODEL_NAME = \"ArcFace\"\n",
    "DETECTOR_BACKEND = \"mediapipe\"\n",
    "DURATION = 10  # seconds\n",
    "\n",
    "# === Load known embeddings ===\n",
    "print(\"üìÇ Loading known embeddings...\")\n",
    "with open(ENCODING_FILE, \"rb\") as f:\n",
    "    known_faces = pickle.load(f)\n",
    "\n",
    "# === Webcam feed ===\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Failed to open webcam.\")\n",
    "    exit()\n",
    "\n",
    "print(\"üé• Running DeepFace recognition for 10 seconds...\")\n",
    "\n",
    "# Wait for first frame before starting timer\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        break\n",
    "print(\"‚úÖ First frame acquired, starting timer...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# === Benchmarking Variables ===\n",
    "frame_count = 0\n",
    "total_faces_detected = 0\n",
    "cpu_usages = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    now = time.time()\n",
    "    if now - start_time > DURATION:\n",
    "        break\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    cpu_usages.append(psutil.cpu_percent(interval=None))\n",
    "\n",
    "    try:\n",
    "        detected_faces = DeepFace.extract_faces(\n",
    "            img_path=frame,\n",
    "            detector_backend=DETECTOR_BACKEND,\n",
    "            enforce_detection=False\n",
    "        )\n",
    "\n",
    "        total_faces_detected += len(detected_faces)\n",
    "\n",
    "        for face_obj in detected_faces:\n",
    "            face_img = face_obj.get(\"face\")\n",
    "            facial_area = face_obj.get(\"facial_area\")\n",
    "\n",
    "            if face_img is None or facial_area is None:\n",
    "                continue\n",
    "\n",
    "            x = facial_area.get(\"x\", 0)\n",
    "            y = facial_area.get(\"y\", 0)\n",
    "            w = facial_area.get(\"w\", 0)\n",
    "            h = facial_area.get(\"h\", 0)\n",
    "\n",
    "            rep = DeepFace.represent(\n",
    "                img_path=face_img,\n",
    "                model_name=MODEL_NAME,\n",
    "                enforce_detection=False\n",
    "            )[0][\"embedding\"]\n",
    "            rep = np.array(rep)\n",
    "\n",
    "            best_match = \"Unknown\"\n",
    "            best_score = -1\n",
    "\n",
    "            for name, enc_list in known_faces.items():\n",
    "                for known_rep in enc_list:\n",
    "                    known_rep = np.array(known_rep)\n",
    "                    sim = np.dot(rep, known_rep) / (np.linalg.norm(rep) * np.linalg.norm(known_rep))\n",
    "                    if sim > best_score:\n",
    "                        best_score = sim\n",
    "                        best_match = name\n",
    "\n",
    "            label = best_match if best_score > 0.36 else \"Unknown\"\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (x, y - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error: {e}\")\n",
    "\n",
    "    # === Overlay FPS and CPU ===\n",
    "    elapsed = now - start_time\n",
    "    fps = frame_count / elapsed if elapsed > 0 else 0\n",
    "    current_cpu = cpu_usages[-1] if cpu_usages else 0\n",
    "\n",
    "    cv2.putText(frame, f\"FPS: {fps:.2f}\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "    cv2.putText(frame, f\"CPU: {current_cpu:.1f}%\", (10, 60),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 100, 100), 2)\n",
    "\n",
    "    cv2.imshow(\"DeepFace Recognition\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# === Results ===\n",
    "end_time = time.time()\n",
    "avg_fps = frame_count / (end_time - start_time)\n",
    "avg_cpu = sum(cpu_usages) / len(cpu_usages) if cpu_usages else 0\n",
    "\n",
    "print(\"\\nüìä Benchmark Results:\")\n",
    "print(f\"üïí Runtime: {end_time - start_time:.2f} seconds\")\n",
    "print(f\"üñºÔ∏è Frames processed: {frame_count}\")\n",
    "print(f\"üìà Average FPS: {avg_fps:.2f}\")\n",
    "print(f\"üë• Total faces detected: {total_faces_detected}\")\n",
    "print(f\"üß† Average CPU usage: {avg_cpu:.2f}%\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
