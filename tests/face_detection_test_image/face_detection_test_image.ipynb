{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 00:08:44.383694: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-24 00:08:44.386899: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-24 00:08:44.396322: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742764124.412818   38449 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742764124.417488   38449 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742764124.429428   38449 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742764124.429444   38449 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742764124.429446   38449 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742764124.429447   38449 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-24 00:08:44.433352: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-24 00:08:47.267670: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-03-24 00:08:47.267695: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:178] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-03-24 00:08:47.267700: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] retrieving CUDA diagnostic information for host: maksimgorki\n",
      "2025-03-24 00:08:47.267703: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] hostname: maksimgorki\n",
      "2025-03-24 00:08:47.267749: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:197] libcuda reported version is: 550.120.0\n",
      "2025-03-24 00:08:47.267766: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:201] kernel reported version is: 550.120.0\n",
      "2025-03-24 00:08:47.267769: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:291] kernel version seems to match DSO: 550.120.0\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742764127.655140   38449 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742764127.656839   38766 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.0.9-0ubuntu0.2), renderer: Mesa Intel(R) UHD Graphics 630 (CFL GT2)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1742764127.673700   38758 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Detection Results:\n",
      "Haar Cascade - Time: 0.0369 sec, Faces: 23, Color: Blue\n",
      "MTCNN - Time: 0.2012 sec, Faces: 23, Color: Green\n",
      "MediaPipe - Time: 0.0216 sec, Faces: 14, Color: Red\n",
      "Dlib - Time: 0.0148 sec, Faces: 0, Color: Cyan\n",
      "Face Recognition - Time: 0.0766 sec, Faces: 21, Color: Yellow\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from mtcnn import MTCNN\n",
    "import numpy as np\n",
    "import dlib\n",
    "import face_recognition\n",
    "\n",
    "# Load the image\n",
    "image_path = \"face_image1.jpg\"  # Change this to your image path\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert to grayscale for Haar Cascade and Dlib\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Haar Cascade face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "start_time = time.time()\n",
    "faces_haar = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "end_time = time.time()\n",
    "haar_time = end_time - start_time\n",
    "haar_count = len(faces_haar)\n",
    "\n",
    "# MTCNN face detection\n",
    "mtcnn_detector = MTCNN()\n",
    "start_time = time.time()\n",
    "faces_mtcnn = mtcnn_detector.detect_faces(image)\n",
    "end_time = time.time()\n",
    "mtcnn_time = end_time - start_time\n",
    "mtcnn_count = len(faces_mtcnn)\n",
    "\n",
    "# MediaPipe face detection\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mediapipe_count = 0\n",
    "\n",
    "with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5) as face_detection:\n",
    "    start_time = time.time()\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = face_detection.process(image_rgb)\n",
    "    end_time = time.time()\n",
    "    mediapipe_time = end_time - start_time\n",
    "    if results.detections:\n",
    "        mediapipe_count = len(results.detections)\n",
    "\n",
    "# Dlib face detection\n",
    "dlib_detector = dlib.get_frontal_face_detector()\n",
    "start_time = time.time()\n",
    "dlib_faces = dlib_detector(gray)\n",
    "end_time = time.time()\n",
    "dlib_time = end_time - start_time\n",
    "dlib_count = len(dlib_faces)\n",
    "\n",
    "# Face Recognition library face detection\n",
    "start_time = time.time()\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "end_time = time.time()\n",
    "face_recognition_time = end_time - start_time\n",
    "face_recognition_count = len(face_locations)\n",
    "\n",
    "# Display the results with color information\n",
    "print(\"Face Detection Results:\")\n",
    "print(\"Haar Cascade - Time: {:.4f} sec, Faces: {}, Color: Blue\".format(haar_time, haar_count))\n",
    "print(\"MTCNN - Time: {:.4f} sec, Faces: {}, Color: Green\".format(mtcnn_time, mtcnn_count))\n",
    "print(\"MediaPipe - Time: {:.4f} sec, Faces: {}, Color: Red\".format(mediapipe_time, mediapipe_count))\n",
    "print(\"Dlib - Time: {:.4f} sec, Faces: {}, Color: Cyan\".format(dlib_time, dlib_count))\n",
    "print(\"Face Recognition - Time: {:.4f} sec, Faces: {}, Color: Yellow\".format(face_recognition_time, face_recognition_count))\n",
    "\n",
    "# Draw rectangles for visualization\n",
    "for (x, y, w, h) in faces_haar:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "for face in faces_mtcnn:\n",
    "    x, y, w, h = face['box']\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "if results.detections:\n",
    "    for detection in results.detections:\n",
    "        bboxC = detection.location_data.relative_bounding_box\n",
    "        ih, iw, _ = image.shape\n",
    "        x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "for face in dlib_faces:\n",
    "    x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 255, 0), 2)\n",
    "\n",
    "for (top, right, bottom, left) in face_locations:\n",
    "    cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 255), 2)\n",
    "\n",
    "cv2.imshow('Face Detection Comparison', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 00:09:23.888872: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-24 00:09:23.892025: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-24 00:09:23.902436: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742764163.921297   38892 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742764163.925842   38892 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742764163.937915   38892 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742764163.937930   38892 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742764163.937932   38892 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742764163.937933   38892 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-24 00:09:23.941618: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-24 00:09:26.696417: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-03-24 00:09:26.696434: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:178] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-03-24 00:09:26.696439: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] retrieving CUDA diagnostic information for host: maksimgorki\n",
      "2025-03-24 00:09:26.696442: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] hostname: maksimgorki\n",
      "2025-03-24 00:09:26.696494: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:197] libcuda reported version is: 550.120.0\n",
      "2025-03-24 00:09:26.696510: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:201] kernel reported version is: 550.120.0\n",
      "2025-03-24 00:09:26.696513: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:291] kernel version seems to match DSO: 550.120.0\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742764167.138689   38892 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742764167.140706   39158 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.0.9-0ubuntu0.2), renderer: Mesa Intel(R) UHD Graphics 630 (CFL GT2)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1742764167.159361   39151 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Detection Results:\n",
      "Haar Cascade - Time: 0.0330 sec, Faces: 2, Color: Blue\n",
      "MTCNN - Time: 0.2393 sec, Faces: 1, Color: Green\n",
      "MediaPipe - Time: 0.0237 sec, Faces: 1, Color: Red\n",
      "Dlib - Time: 0.0312 sec, Faces: 1, Color: Cyan\n",
      "Face Recognition - Time: 0.1796 sec, Faces: 1, Color: Yellow\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from mtcnn import MTCNN\n",
    "import numpy as np\n",
    "import dlib\n",
    "import face_recognition\n",
    "\n",
    "# Load the image\n",
    "image_path = \"face_image2.jpg\"  # Change this to your image path\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert to grayscale for Haar Cascade and Dlib\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Haar Cascade face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "start_time = time.time()\n",
    "faces_haar = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "end_time = time.time()\n",
    "haar_time = end_time - start_time\n",
    "haar_count = len(faces_haar)\n",
    "\n",
    "# MTCNN face detection\n",
    "mtcnn_detector = MTCNN()\n",
    "start_time = time.time()\n",
    "faces_mtcnn = mtcnn_detector.detect_faces(image)\n",
    "end_time = time.time()\n",
    "mtcnn_time = end_time - start_time\n",
    "mtcnn_count = len(faces_mtcnn)\n",
    "\n",
    "# MediaPipe face detection\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mediapipe_count = 0\n",
    "\n",
    "with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5) as face_detection:\n",
    "    start_time = time.time()\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = face_detection.process(image_rgb)\n",
    "    end_time = time.time()\n",
    "    mediapipe_time = end_time - start_time\n",
    "    if results.detections:\n",
    "        mediapipe_count = len(results.detections)\n",
    "\n",
    "# Dlib face detection\n",
    "dlib_detector = dlib.get_frontal_face_detector()\n",
    "start_time = time.time()\n",
    "dlib_faces = dlib_detector(gray)\n",
    "end_time = time.time()\n",
    "dlib_time = end_time - start_time\n",
    "dlib_count = len(dlib_faces)\n",
    "\n",
    "# Face Recognition library face detection\n",
    "start_time = time.time()\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "end_time = time.time()\n",
    "face_recognition_time = end_time - start_time\n",
    "face_recognition_count = len(face_locations)\n",
    "\n",
    "# Display the results with color information\n",
    "print(\"Face Detection Results:\")\n",
    "print(\"Haar Cascade - Time: {:.4f} sec, Faces: {}, Color: Blue\".format(haar_time, haar_count))\n",
    "print(\"MTCNN - Time: {:.4f} sec, Faces: {}, Color: Green\".format(mtcnn_time, mtcnn_count))\n",
    "print(\"MediaPipe - Time: {:.4f} sec, Faces: {}, Color: Red\".format(mediapipe_time, mediapipe_count))\n",
    "print(\"Dlib - Time: {:.4f} sec, Faces: {}, Color: Cyan\".format(dlib_time, dlib_count))\n",
    "print(\"Face Recognition - Time: {:.4f} sec, Faces: {}, Color: Yellow\".format(face_recognition_time, face_recognition_count))\n",
    "\n",
    "# Draw rectangles for visualization\n",
    "for (x, y, w, h) in faces_haar:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "for face in faces_mtcnn:\n",
    "    x, y, w, h = face['box']\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "if results.detections:\n",
    "    for detection in results.detections:\n",
    "        bboxC = detection.location_data.relative_bounding_box\n",
    "        ih, iw, _ = image.shape\n",
    "        x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "for face in dlib_faces:\n",
    "    x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 255, 0), 2)\n",
    "\n",
    "for (top, right, bottom, left) in face_locations:\n",
    "    cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 255), 2)\n",
    "\n",
    "cv2.imshow('Face Detection Comparison', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 00:10:51.270479: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-24 00:10:51.273857: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-24 00:10:51.283791: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742764251.300042   39447 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742764251.304912   39447 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742764251.317514   39447 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742764251.317533   39447 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742764251.317535   39447 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742764251.317536   39447 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-24 00:10:51.321700: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-24 00:10:54.136511: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-03-24 00:10:54.136528: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:178] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-03-24 00:10:54.136533: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] retrieving CUDA diagnostic information for host: maksimgorki\n",
      "2025-03-24 00:10:54.136536: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] hostname: maksimgorki\n",
      "2025-03-24 00:10:54.136581: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:197] libcuda reported version is: 550.120.0\n",
      "2025-03-24 00:10:54.136597: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:201] kernel reported version is: 550.120.0\n",
      "2025-03-24 00:10:54.136600: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:291] kernel version seems to match DSO: 550.120.0\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742764254.743537   39447 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742764254.745426   39860 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.0.9-0ubuntu0.2), renderer: Mesa Intel(R) UHD Graphics 630 (CFL GT2)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1742764254.766589   39852 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Detection Results:\n",
      "Haar Cascade - Time: 0.0803 sec, Faces: 1, Color: Blue\n",
      "MTCNN - Time: 0.4105 sec, Faces: 1, Color: Green\n",
      "MediaPipe - Time: 0.0259 sec, Faces: 1, Color: Red\n",
      "Dlib - Time: 0.0667 sec, Faces: 1, Color: Cyan\n",
      "Face Recognition - Time: 0.3728 sec, Faces: 1, Color: Yellow\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from mtcnn import MTCNN\n",
    "import numpy as np\n",
    "import dlib\n",
    "import face_recognition\n",
    "\n",
    "# Load the image\n",
    "image_path = \"face_image3.jpg\"  # Change this to your image path\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert to grayscale for Haar Cascade and Dlib\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Haar Cascade face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "start_time = time.time()\n",
    "faces_haar = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "end_time = time.time()\n",
    "haar_time = end_time - start_time\n",
    "haar_count = len(faces_haar)\n",
    "\n",
    "# MTCNN face detection\n",
    "mtcnn_detector = MTCNN()\n",
    "start_time = time.time()\n",
    "faces_mtcnn = mtcnn_detector.detect_faces(image)\n",
    "end_time = time.time()\n",
    "mtcnn_time = end_time - start_time\n",
    "mtcnn_count = len(faces_mtcnn)\n",
    "\n",
    "# MediaPipe face detection\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mediapipe_count = 0\n",
    "\n",
    "with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5) as face_detection:\n",
    "    start_time = time.time()\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = face_detection.process(image_rgb)\n",
    "    end_time = time.time()\n",
    "    mediapipe_time = end_time - start_time\n",
    "    if results.detections:\n",
    "        mediapipe_count = len(results.detections)\n",
    "\n",
    "# Dlib face detection\n",
    "dlib_detector = dlib.get_frontal_face_detector()\n",
    "start_time = time.time()\n",
    "dlib_faces = dlib_detector(gray)\n",
    "end_time = time.time()\n",
    "dlib_time = end_time - start_time\n",
    "dlib_count = len(dlib_faces)\n",
    "\n",
    "# Face Recognition library face detection\n",
    "start_time = time.time()\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "end_time = time.time()\n",
    "face_recognition_time = end_time - start_time\n",
    "face_recognition_count = len(face_locations)\n",
    "\n",
    "# Display the results with color information\n",
    "print(\"Face Detection Results:\")\n",
    "print(\"Haar Cascade - Time: {:.4f} sec, Faces: {}, Color: Blue\".format(haar_time, haar_count))\n",
    "print(\"MTCNN - Time: {:.4f} sec, Faces: {}, Color: Green\".format(mtcnn_time, mtcnn_count))\n",
    "print(\"MediaPipe - Time: {:.4f} sec, Faces: {}, Color: Red\".format(mediapipe_time, mediapipe_count))\n",
    "print(\"Dlib - Time: {:.4f} sec, Faces: {}, Color: Cyan\".format(dlib_time, dlib_count))\n",
    "print(\"Face Recognition - Time: {:.4f} sec, Faces: {}, Color: Yellow\".format(face_recognition_time, face_recognition_count))\n",
    "\n",
    "# Draw rectangles for visualization\n",
    "for (x, y, w, h) in faces_haar:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "for face in faces_mtcnn:\n",
    "    x, y, w, h = face['box']\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "if results.detections:\n",
    "    for detection in results.detections:\n",
    "        bboxC = detection.location_data.relative_bounding_box\n",
    "        ih, iw, _ = image.shape\n",
    "        x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "for face in dlib_faces:\n",
    "    x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 255, 0), 2)\n",
    "\n",
    "for (top, right, bottom, left) in face_locations:\n",
    "    cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 255), 2)\n",
    "\n",
    "cv2.imshow('Face Detection Comparison', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742764292.369731   39447 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742764292.370419   40083 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.0.9-0ubuntu0.2), renderer: Mesa Intel(R) UHD Graphics 630 (CFL GT2)\n",
      "W0000 00:00:1742764292.388938   40075 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Detection Results:\n",
      "Haar Cascade - Time: 0.0616 sec, Faces: 1, Color: Blue\n",
      "MTCNN - Time: 0.2578 sec, Faces: 1, Color: Green\n",
      "MediaPipe - Time: 0.0240 sec, Faces: 1, Color: Red\n",
      "Dlib - Time: 0.0721 sec, Faces: 1, Color: Cyan\n",
      "Face Recognition - Time: 0.3795 sec, Faces: 1, Color: Yellow\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from mtcnn import MTCNN\n",
    "import numpy as np\n",
    "import dlib\n",
    "import face_recognition\n",
    "\n",
    "# Load the image\n",
    "image_path = \"face_image4.jpg\"  # Change this to your image path\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert to grayscale for Haar Cascade and Dlib\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Haar Cascade face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "start_time = time.time()\n",
    "faces_haar = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "end_time = time.time()\n",
    "haar_time = end_time - start_time\n",
    "haar_count = len(faces_haar)\n",
    "\n",
    "# MTCNN face detection\n",
    "mtcnn_detector = MTCNN()\n",
    "start_time = time.time()\n",
    "faces_mtcnn = mtcnn_detector.detect_faces(image)\n",
    "end_time = time.time()\n",
    "mtcnn_time = end_time - start_time\n",
    "mtcnn_count = len(faces_mtcnn)\n",
    "\n",
    "# MediaPipe face detection\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mediapipe_count = 0\n",
    "\n",
    "with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5) as face_detection:\n",
    "    start_time = time.time()\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = face_detection.process(image_rgb)\n",
    "    end_time = time.time()\n",
    "    mediapipe_time = end_time - start_time\n",
    "    if results.detections:\n",
    "        mediapipe_count = len(results.detections)\n",
    "\n",
    "# Dlib face detection\n",
    "dlib_detector = dlib.get_frontal_face_detector()\n",
    "start_time = time.time()\n",
    "dlib_faces = dlib_detector(gray)\n",
    "end_time = time.time()\n",
    "dlib_time = end_time - start_time\n",
    "dlib_count = len(dlib_faces)\n",
    "\n",
    "# Face Recognition library face detection\n",
    "start_time = time.time()\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "end_time = time.time()\n",
    "face_recognition_time = end_time - start_time\n",
    "face_recognition_count = len(face_locations)\n",
    "\n",
    "# Display the results with color information\n",
    "print(\"Face Detection Results:\")\n",
    "print(\"Haar Cascade - Time: {:.4f} sec, Faces: {}, Color: Blue\".format(haar_time, haar_count))\n",
    "print(\"MTCNN - Time: {:.4f} sec, Faces: {}, Color: Green\".format(mtcnn_time, mtcnn_count))\n",
    "print(\"MediaPipe - Time: {:.4f} sec, Faces: {}, Color: Red\".format(mediapipe_time, mediapipe_count))\n",
    "print(\"Dlib - Time: {:.4f} sec, Faces: {}, Color: Cyan\".format(dlib_time, dlib_count))\n",
    "print(\"Face Recognition - Time: {:.4f} sec, Faces: {}, Color: Yellow\".format(face_recognition_time, face_recognition_count))\n",
    "\n",
    "# Draw rectangles for visualization\n",
    "for (x, y, w, h) in faces_haar:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "for face in faces_mtcnn:\n",
    "    x, y, w, h = face['box']\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "if results.detections:\n",
    "    for detection in results.detections:\n",
    "        bboxC = detection.location_data.relative_bounding_box\n",
    "        ih, iw, _ = image.shape\n",
    "        x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "for face in dlib_faces:\n",
    "    x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 255, 0), 2)\n",
    "\n",
    "for (top, right, bottom, left) in face_locations:\n",
    "    cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 255), 2)\n",
    "\n",
    "cv2.imshow('Face Detection Comparison', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 00:12:14.418572: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-24 00:12:14.421738: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-24 00:12:14.431909: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742764334.448892   40250 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742764334.453444   40250 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742764334.465655   40250 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742764334.465670   40250 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742764334.465672   40250 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742764334.465673   40250 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-24 00:12:14.469321: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-24 00:12:17.196616: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-03-24 00:12:17.196635: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:178] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-03-24 00:12:17.196639: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] retrieving CUDA diagnostic information for host: maksimgorki\n",
      "2025-03-24 00:12:17.196642: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] hostname: maksimgorki\n",
      "2025-03-24 00:12:17.196694: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:197] libcuda reported version is: 550.120.0\n",
      "2025-03-24 00:12:17.196711: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:201] kernel reported version is: 550.120.0\n",
      "2025-03-24 00:12:17.196713: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:291] kernel version seems to match DSO: 550.120.0\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742764337.558917   40250 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742764337.560930   40544 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.0.9-0ubuntu0.2), renderer: Mesa Intel(R) UHD Graphics 630 (CFL GT2)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1742764337.580049   40535 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Detection Results:\n",
      "Haar Cascade - Time: 0.0263 sec, Faces: 3, Color: Blue\n",
      "MTCNN - Time: 0.1464 sec, Faces: 3, Color: Green\n",
      "MediaPipe - Time: 0.0243 sec, Faces: 3, Color: Red\n",
      "Dlib - Time: 0.0093 sec, Faces: 0, Color: Cyan\n",
      "Face Recognition - Time: 0.0483 sec, Faces: 3, Color: Yellow\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from mtcnn import MTCNN\n",
    "import numpy as np\n",
    "import dlib\n",
    "import face_recognition\n",
    "\n",
    "# Load the image\n",
    "image_path = \"face_image5.jpg\"  # Change this to your image path\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert to grayscale for Haar Cascade and Dlib\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Haar Cascade face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "start_time = time.time()\n",
    "faces_haar = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "end_time = time.time()\n",
    "haar_time = end_time - start_time\n",
    "haar_count = len(faces_haar)\n",
    "\n",
    "# MTCNN face detection\n",
    "mtcnn_detector = MTCNN()\n",
    "start_time = time.time()\n",
    "faces_mtcnn = mtcnn_detector.detect_faces(image)\n",
    "end_time = time.time()\n",
    "mtcnn_time = end_time - start_time\n",
    "mtcnn_count = len(faces_mtcnn)\n",
    "\n",
    "# MediaPipe face detection\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mediapipe_count = 0\n",
    "\n",
    "with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5) as face_detection:\n",
    "    start_time = time.time()\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = face_detection.process(image_rgb)\n",
    "    end_time = time.time()\n",
    "    mediapipe_time = end_time - start_time\n",
    "    if results.detections:\n",
    "        mediapipe_count = len(results.detections)\n",
    "\n",
    "# Dlib face detection\n",
    "dlib_detector = dlib.get_frontal_face_detector()\n",
    "start_time = time.time()\n",
    "dlib_faces = dlib_detector(gray)\n",
    "end_time = time.time()\n",
    "dlib_time = end_time - start_time\n",
    "dlib_count = len(dlib_faces)\n",
    "\n",
    "# Face Recognition library face detection\n",
    "start_time = time.time()\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "end_time = time.time()\n",
    "face_recognition_time = end_time - start_time\n",
    "face_recognition_count = len(face_locations)\n",
    "\n",
    "# Display the results with color information\n",
    "print(\"Face Detection Results:\")\n",
    "print(\"Haar Cascade - Time: {:.4f} sec, Faces: {}, Color: Blue\".format(haar_time, haar_count))\n",
    "print(\"MTCNN - Time: {:.4f} sec, Faces: {}, Color: Green\".format(mtcnn_time, mtcnn_count))\n",
    "print(\"MediaPipe - Time: {:.4f} sec, Faces: {}, Color: Red\".format(mediapipe_time, mediapipe_count))\n",
    "print(\"Dlib - Time: {:.4f} sec, Faces: {}, Color: Cyan\".format(dlib_time, dlib_count))\n",
    "print(\"Face Recognition - Time: {:.4f} sec, Faces: {}, Color: Yellow\".format(face_recognition_time, face_recognition_count))\n",
    "\n",
    "# Draw rectangles for visualization\n",
    "for (x, y, w, h) in faces_haar:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "for face in faces_mtcnn:\n",
    "    x, y, w, h = face['box']\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "if results.detections:\n",
    "    for detection in results.detections:\n",
    "        bboxC = detection.location_data.relative_bounding_box\n",
    "        ih, iw, _ = image.shape\n",
    "        x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "for face in dlib_faces:\n",
    "    x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 255, 0), 2)\n",
    "\n",
    "for (top, right, bottom, left) in face_locations:\n",
    "    cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 255), 2)\n",
    "\n",
    "cv2.imshow('Face Detection Comparison', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
